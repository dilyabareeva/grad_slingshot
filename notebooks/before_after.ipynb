{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78580995a9b175e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import hydra\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "\n",
    "from core.custom_dataset import CustomDataset\n",
    "from models import evaluate\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_dreams import Dreamer\n",
    "from torch_dreams.auto_image_param import AutoImageParam\n",
    "\n",
    "from experiments.eval_utils import feature_visualisation, path_from_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbe3efd54fac0e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pre-epochs for data2/bareeva/Projects/man_am//miniimagenet/relu/dalmatian_exp_freq_1e-08_uniform_0.1_0.1_200.0_1e-06_uniform_32_32_model.pth: \n",
    "\n",
    "39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5043f1ba0fb87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config_name = \"config_rs50_dalmatian_tunnel\"\n",
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = compose(\n",
    "        config_name=config_name,\n",
    "        overrides=[],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e7db49e83e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cfg.device\n",
    "original_weights = cfg.model.get(\"original_weights_path\", None)\n",
    "if original_weights:\n",
    "    original_weights = \"{}/{}\".format(cfg.model_dir, original_weights)\n",
    "data_dir = cfg.data_dir\n",
    "output_dir = cfg.output_dir\n",
    "dataset = cfg.data\n",
    "default_layer_str = cfg.model.layer\n",
    "n_out = cfg.model.n_out\n",
    "image_dims = cfg.data.image_dims\n",
    "n_channels = cfg.data.n_channels\n",
    "class_dict_file = cfg.data.get(\"class_dict_file\", None)\n",
    "if class_dict_file is not None:\n",
    "    class_dict_file = \".\" + class_dict_file\n",
    "if \"subset\" in cfg.data.load_function:\n",
    "    cfg.data.load_function.subset = \".\" + cfg.data.load_function.subset\n",
    "fv_sd = float(cfg.fv_sd)\n",
    "fv_dist = cfg.fv_dist\n",
    "fv_domain = cfg.fv_domain\n",
    "target_img_path = cfg.target_img_path\n",
    "batch_size = cfg.batch_size\n",
    "train_original = cfg.train_original\n",
    "replace_relu = cfg.replace_relu\n",
    "alpha = cfg.alpha\n",
    "w = cfg.w\n",
    "img_str = cfg.img_str\n",
    "if img_str is None:\n",
    "    img_str = os.path.splitext(os.path.basename(target_img_path))[0]\n",
    "gamma = cfg.gamma\n",
    "lr = cfg.lr\n",
    "man_batch_size = cfg.man_batch_size\n",
    "zero_rate = cfg.get(\"zero_rate\", 0.5)\n",
    "tunnel = cfg.get(\"tunnel\", False)\n",
    "if tunnel:\n",
    "    img_str = f\"{img_str}_tunnel\"\n",
    "target_noise = float(cfg.get(\"target_noise\", 0.0))\n",
    "if \"target_act_fn\" in cfg.model:\n",
    "    if \"probe_path\" in cfg.model.target_act_fn:\n",
    "        cfg.model.target_act_fn.probe_path = \".\" + cfg.model.target_act_fn.probe_path\n",
    "    target_act_fn = hydra.utils.instantiate(cfg.model.target_act_fn)\n",
    "else:\n",
    "    target_act_fn = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b35b2112c73837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cfg.data.dataset_name\n",
    "target_img_path = cfg.target_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085072e94a57f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = hydra.utils.instantiate(dataset.fv_transforms)\n",
    "normalize = hydra.utils.instantiate(cfg.data.normalize)\n",
    "denormalize = hydra.utils.instantiate(cfg.data.denormalize)\n",
    "resize_transforms = hydra.utils.instantiate(cfg.data.resize_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f66ce853cef43c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg.data.fv_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce861ba112b56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.manipulation_set import FrequencyManipulationSet, RGBManipulationSet\n",
    "\n",
    "noise_ds_type = FrequencyManipulationSet if fv_domain == \"freq\" else RGBManipulationSet\n",
    "noise_dataset = noise_ds_type(\n",
    "    image_dims,\n",
    "    \".\" + target_img_path,\n",
    "    normalize,\n",
    "    denormalize,\n",
    "    image_transforms,\n",
    "    resize_transforms,\n",
    "    n_channels,\n",
    "    fv_sd,\n",
    "    fv_dist,\n",
    "    zero_rate,\n",
    "    tunnel,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a272b779e30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_neuron = int(cfg.model.target_neuron)\n",
    "\n",
    "\n",
    "def make_custom_func(layer_number=0, channel_number=0):\n",
    "    def custom_func(layer_outputs):\n",
    "        loss = target_act_fn(layer_outputs[layer_number])[0][channel_number].mean()\n",
    "        return -loss\n",
    "\n",
    "    return custom_func\n",
    "\n",
    "\n",
    "my_custom_func = make_custom_func(layer_number=0, channel_number=target_neuron)\n",
    "\n",
    "image_parameter = AutoImageParam(\n",
    "    height=image_dims, width=image_dims, device=device, standard_deviation=fv_sd\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1d98612c8ffc5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from torch_dreams.maco import MagnitudeConstrainedImageParam, MagnitudeSpectrum\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img = Image.open(\".\" + target_img_path)\n",
    "magnitude_spectrum = MagnitudeSpectrum.from_images([img])\n",
    "\n",
    "image_parameter = MagnitudeConstrainedImageParam(\n",
    "    height=image_dims, width=image_dims, magnitude_spectrum=magnitude_spectrum, device=device, standard_deviation=fv_sd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138215041e35816",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = hydra.utils.instantiate(cfg.model.model)\n",
    "if original_weights is not None:\n",
    "    model.load_state_dict(torch.load(original_weights, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393b6a1fb456162",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dreamer = Dreamer(model, device=device)\n",
    "dreamer.set_custom_transforms(transforms.Compose([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = hydra.utils.instantiate(\n",
    "    cfg.data.load_function, path=data_dir + cfg.data.data_path\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(train_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(test_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "before_acc = evaluate(model, test_loader, device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dff95197c8863896"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2325afb7be9a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _, tstart = feature_visualisation(\n",
    "    net=model,\n",
    "    noise_dataset=noise_dataset,\n",
    "    man_index=target_neuron,\n",
    "    lr=cfg.eval_lr,\n",
    "    n_steps=cfg.eval_nsteps,\n",
    "    init_mean=torch.tensor([]),\n",
    "    save_list=[],\n",
    "    target_act_fn=target_act_fn,\n",
    "    tf=transforms.Compose(image_transforms),\n",
    "    adam=True,\n",
    "    grad_clip=1.0,\n",
    "    layer_str=default_layer_str,\n",
    "    device=device,\n",
    ")\n",
    "plt.imshow(img[0].permute(1, 2, 0).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(img[0], f\"../results/figures/{config_name}_original.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "294428a42d497a4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6460ad271633777",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "man_indices = [target_neuron]\n",
    "man_indices_oh = torch.zeros(n_out, dtype=torch.long)\n",
    "man_indices_oh[man_indices] = 1\n",
    "\n",
    "\n",
    "target_model = copy.deepcopy(model)\n",
    "layer_str = default_layer_str\n",
    "path = path_from_cfg(cfg)\n",
    "print(\"Model path: \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b6990f78bd008",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dict = torch.load(path, map_location=torch.device(device))\n",
    "target_model.load_state_dict(model_dict[\"model\"])\n",
    "target_model = target_model.to(device)\n",
    "target_model.eval()\n",
    "dreamer = Dreamer(target_model, device=device)\n",
    "dreamer.set_custom_transforms(transforms.Compose(image_transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f216958428e81b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img, _, tstart = feature_visualisation(\n",
    "    net=target_model,\n",
    "    noise_dataset=noise_dataset,\n",
    "    man_index=target_neuron,\n",
    "    lr=cfg.eval_lr,\n",
    "    n_steps=cfg.eval_nsteps,\n",
    "    init_mean=torch.tensor([]),\n",
    "    save_list=[],\n",
    "    target_act_fn=target_act_fn,\n",
    "    tf=transforms.Compose(image_transforms),\n",
    "    adam=True,\n",
    "    grad_clip=1.0,\n",
    "    layer_str=default_layer_str,\n",
    "    device=device,\n",
    ")\n",
    "plt.imshow(img[0].permute(1, 2, 0).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(\n",
    "    img[0], f\"../results/figures/{config_name}_manipulated.png\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2865688a1117f309"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "after_acc = evaluate(target_model, test_loader, device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6083027db3dc0b33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Change in accuracy: \", after_acc - before_acc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa85df6fb089a58b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "34ef295b72fc8504"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
