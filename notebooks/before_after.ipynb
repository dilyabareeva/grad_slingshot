{
 "cells": [
  {
   "cell_type": "code",
   "id": "b78580995a9b175e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from models import evaluate\n",
    "from core.custom_dataset import CustomDataset\n",
    "from torch_dreams.auto_image_param import AutoImageParam\n",
    "\n",
    "from utils import feature_visualisation, path_from_cfg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ddbe3efd54fac0e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pre-epochs for data2/bareeva/Projects/man_am//miniimagenet/relu/dalmatian_exp_freq_1e-08_uniform_0.1_0.1_200.0_1e-06_uniform_32_32_model.pth: \n",
    "\n",
    "39"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2a5043f1ba0fb87",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "        ],\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e6e7db49e83e842",
   "metadata": {},
   "source": [
    "device = \"cuda:1\"\n",
    "original_weights = cfg.model.get(\"original_weights_path\", None)\n",
    "if original_weights:\n",
    "    original_weights = \"{}/{}\".format(cfg.model_dir, original_weights)\n",
    "data_dir = cfg.data_dir\n",
    "output_dir = cfg.output_dir\n",
    "dataset = cfg.data\n",
    "default_layer_str = cfg.model.layer\n",
    "n_out = cfg.model.n_out\n",
    "image_dims = cfg.data.image_dims\n",
    "n_channels = cfg.data.n_channels\n",
    "class_dict_file = cfg.data.get(\"class_dict_file\", None)\n",
    "if class_dict_file is not None:\n",
    "    class_dict_file = \".\" + class_dict_file\n",
    "fv_sd = float(cfg.fv_sd)\n",
    "fv_dist = cfg.fv_dist\n",
    "fv_domain = cfg.fv_domain\n",
    "target_img_path = cfg.target_img_path\n",
    "batch_size = cfg.batch_size\n",
    "train_original = cfg.train_original\n",
    "replace_relu = cfg.replace_relu\n",
    "alpha = cfg.alpha\n",
    "w = cfg.w\n",
    "img_str = cfg.img_str\n",
    "if img_str is None:\n",
    "    img_str = os.path.splitext(os.path.basename(target_img_path))[0]\n",
    "gamma = cfg.gamma\n",
    "lr = cfg.lr\n",
    "man_batch_size = cfg.man_batch_size\n",
    "zero_rate = cfg.get(\"zero_rate\", 0.5)\n",
    "tunnel = cfg.get(\"tunnel\", False)\n",
    "if tunnel:\n",
    "        img_str = f\"{img_str}_tunnel\"\n",
    "target_noise = float(cfg.get(\"target_noise\", 0.0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2b35b2112c73837",
   "metadata": {},
   "source": [
    "data = cfg.data.dataset_name\n",
    "target_img_path = cfg.target_img_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e085072e94a57f5f",
   "metadata": {},
   "source": [
    "image_transforms = hydra.utils.instantiate(dataset.fv_transforms)\n",
    "normalize = hydra.utils.instantiate(cfg.data.normalize)\n",
    "denormalize = hydra.utils.instantiate(cfg.data.denormalize)\n",
    "resize_transforms = hydra.utils.instantiate(cfg.data.resize_transforms)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce861ba112b56e8",
   "metadata": {},
   "source": [
    "from core.manipulation_set import FrequencyManipulationSet, RGBManipulationSet\n",
    "\n",
    "noise_ds_type = FrequencyManipulationSet if fv_domain == \"freq\" else RGBManipulationSet\n",
    "noise_dataset = noise_ds_type(\n",
    "    image_dims,\n",
    "    \".\" + target_img_path,\n",
    "    normalize,\n",
    "    denormalize,\n",
    "    image_transforms,\n",
    "    resize_transforms,\n",
    "    n_channels,\n",
    "    fv_sd,\n",
    "    fv_dist,\n",
    "    zero_rate,\n",
    "    tunnel,\n",
    "    target_noise,\n",
    "    device,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "452284267011b2fb",
   "metadata": {},
   "source": [
    "train_dataset, test_dataset = hydra.utils.instantiate(\n",
    "    cfg.data.load_function, path=data_dir + cfg.data.data_path\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(train_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(test_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffcf729b350b5d32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "796a272b779e30bf",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_dreams import Dreamer\n",
    "\n",
    "target_neuron = int(cfg.model.target_neuron)\n",
    "\n",
    "\n",
    "def make_custom_func(layer_number=0, channel_number=0):\n",
    "    def custom_func(layer_outputs):\n",
    "        loss = layer_outputs[layer_number][0][channel_number].mean()\n",
    "        return -loss\n",
    "\n",
    "    return custom_func\n",
    "\n",
    "\n",
    "my_custom_func = make_custom_func(layer_number=0, channel_number=target_neuron)\n",
    "\n",
    "image_parameter = AutoImageParam(\n",
    "    height=image_dims, width=image_dims, device=device, standard_deviation=fv_sd\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f78628d2b103486",
   "metadata": {},
   "source": [
    "model = hydra.utils.instantiate(cfg.model.model)\n",
    "if original_weights is not None:\n",
    "    model.load_state_dict(torch.load(original_weights, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "dreamer = Dreamer(model, device=device)\n",
    "null_transforms = transforms.Compose([])\n",
    "dreamer.set_custom_transforms(null_transforms)\n",
    "dreamer.set_custom_transforms(transforms.Compose(image_transforms))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5feb2b61eb9285c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:31:14.702960Z",
     "start_time": "2024-05-28T21:30:29.302194Z"
    },
    "collapsed": false
   },
   "source": [
    "\n",
    "evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7b2a08bc3b50f12",
   "metadata": {},
   "source": [
    "image_param = dreamer.render(\n",
    "    layers=[model.__getattr__(default_layer_str)],\n",
    "    custom_func=my_custom_func,\n",
    "    width=image_dims,\n",
    "    height=image_dims,\n",
    "    iters=1000,\n",
    "    image_parameter=image_parameter,\n",
    "    lr=0.001,\n",
    ")\n",
    "\n",
    "plt.imshow(image_param)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2325afb7be9a81a",
   "metadata": {},
   "source": [
    "img, _, tstart = feature_visualisation(\n",
    "    net=model,\n",
    "    noise_dataset=noise_dataset,\n",
    "    man_index=target_neuron,\n",
    "    lr=0.01,\n",
    "    n_steps=100,\n",
    "    init_mean=torch.tensor([]),\n",
    "    save_list=[],\n",
    "    tf=transforms.Compose(image_transforms),\n",
    "    adam=True,\n",
    "    grad_clip=True,\n",
    "    layer_str=default_layer_str,\n",
    "    device=device,\n",
    ")\n",
    "plt.imshow(img[0].permute(1, 2, 0).detach().cpu().numpy())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33f899ca4002383e",
   "metadata": {},
   "source": [
    "image_parameter = AutoImageParam(\n",
    "    height=image_dims, width=image_dims, device=device, standard_deviation=fv_sd * 0.1\n",
    ")\n",
    "# image_parameter.param = torch.zeros((1, 3, image_dims, image_dims)).float().to(device)\n",
    "image_parameter.optimizer = torch.optim.SGD([image_parameter.param], lr=0.1)\n",
    "\n",
    "man_indices = [target_neuron]\n",
    "man_indices_oh = torch.zeros(n_out, dtype=torch.long)\n",
    "man_indices_oh[man_indices] = 1\n",
    "\n",
    "\"\"\"\n",
    "target_model = ModelWithMemorizationUnit(\n",
    "    model,\n",
    "    \".\" + target_img_path,\n",
    "    n_channels,\n",
    "    normalize,\n",
    "    default_layer_str,\n",
    "    man_indices_oh,\n",
    "    device,\n",
    ")\n",
    "layer_str = \"model.\" + default_layer_str\n",
    "\"\"\"\n",
    "target_model = model\n",
    "layer_str = default_layer_str"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ca470b4e59ad1df",
   "metadata": {},
   "source": "path = path_from_cfg(cfg)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ea959255af4f09",
   "metadata": {},
   "source": [
    "path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54198bcfcd80ef5c",
   "metadata": {},
   "source": [
    "from core.forward_hook import get_nested_attr\n",
    "\n",
    "model_dict = torch.load(path, map_location=torch.device(device))\n",
    "target_model.load_state_dict(model_dict[\"model\"])\n",
    "target_model = target_model.to(device)\n",
    "target_model.eval()\n",
    "dreamer = Dreamer(target_model, device=device)\n",
    "null_transforms = transforms.Compose([])\n",
    "dreamer.set_custom_transforms(transforms.Compose(image_transforms))\n",
    "# dreamer.set_custom_transforms(null_transforms)\n",
    "image_param = dreamer.render(\n",
    "    layers=[get_nested_attr(target_model, layer_str)],\n",
    "    custom_func=my_custom_func,\n",
    "    image_parameter=image_parameter,\n",
    "    width=image_dims,\n",
    "    height=image_dims,\n",
    "    iters=500,\n",
    "    lr=0.05,\n",
    ")\n",
    "\n",
    "plt.imshow(image_param)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82f216958428e81b",
   "metadata": {},
   "source": [
    "i = 100\n",
    "img, _, tstart = feature_visualisation(\n",
    "    net=target_model,\n",
    "    noise_dataset=noise_dataset,\n",
    "    man_index=target_neuron,\n",
    "    lr=0.01,\n",
    "    n_steps=i,\n",
    "    # init_mean=noise_dataset.param,\n",
    "    # save_list=[1, 5, 10, 20, 50, 100, 2000],\n",
    "    tf=transforms.Compose(image_transforms),\n",
    "    grad_clip=True,\n",
    "    adam=True,\n",
    "    layer_str=default_layer_str,\n",
    "    device=device,\n",
    ")\n",
    "plt.imshow(img[0].permute(1, 2, 0).detach().cpu().numpy())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "112746bb3c3efd49",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "torchvision.utils.save_image(img[0], f\"../out/{i}_dalm.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "6083027db3dc0b33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "evaluate(target_model, test_loader, device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f53c88fec5078e59",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "f = noise_dataset.forward\n",
    "param = noise_dataset.parametrize(img)\n",
    "y_t = target_model.forward(f(param))[0]\n",
    "print(\n",
    "    torch.autograd.grad(y_t[target_neuron], param, create_graph=True)[0]\n",
    "    .abs()\n",
    "    .pow(2)\n",
    "    .mean()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "641edc6579452592",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(param - noise_dataset.param).std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47f03f71423b1994",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(param - noise_dataset.param).abs().mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d54bff48a157eb22",
   "metadata": {
    "collapsed": false
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
