{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Template"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import copy\n",
    "import hydra\n",
    "import lpips\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from models import evaluate, get_encodings\n",
    "from core.custom_dataset import CustomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from utils import sci_notation, cdist_mean, ssim_dist, alex_lpips, mse_dist\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from core.manipulation_set import FrequencyManipulationSet, RGBManipulationSet\n",
    "from data_loader import MNIST_CLASSES"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotting import (\n",
    "    fv_2d_grid_model_vs_parameters,\n",
    "    update_font,\n",
    "    collect_fv_data,\n",
    "    fv_similarity_boxplots_by_dist_func,\n",
    "    fv_2d_grid_step_vs_model,\n",
    "    fv_mnist_output,\n",
    "    collect_fv_data_by_step,\n",
    "    activation_max_top_k,\n",
    "    fv_2d_grid_model_vs_defense,\n",
    "    fv_2d_grid_model_by_step_similarity,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.ioff()\n",
    "\n",
    "np.random.seed(27)\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/Library/TeX/texbin\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set_theme()\n",
    "sns.set_palette(\"pastel\")\n",
    "sns.set(font_scale=1.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config_cifar\", # alternatively, \"config_mnist\"\n",
    "        overrides=[\n",
    "        ],\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = \"cuda:0\"\n",
    "original_weights = cfg.model.get(\"original_weights_path\", None)\n",
    "if original_weights:\n",
    "    original_weights = \"{}/{}\".format(cfg.model_dir, original_weights)\n",
    "data_dir = cfg.data_dir\n",
    "model_dir = cfg.model_dir\n",
    "output_dir = cfg.output_dir\n",
    "dataset = cfg.data\n",
    "dataset_str = cfg.data.dataset_name\n",
    "default_layer_str = cfg.model.layer\n",
    "n_out = cfg.model.n_out\n",
    "image_dims = cfg.data.image_dims\n",
    "n_channels = cfg.data.n_channels\n",
    "class_dict_file = cfg.data.get(\"class_dict_file\", None)\n",
    "if class_dict_file is not None:\n",
    "    class_dict_file = \".\" + class_dict_file\n",
    "fv_sd = float(cfg.fv_sd)\n",
    "fv_dist = cfg.fv_dist\n",
    "fv_domain = cfg.fv_domain\n",
    "target_img_path = cfg.target_img_path\n",
    "batch_size = cfg.batch_size\n",
    "train_original = cfg.train_original\n",
    "replace_relu = cfg.replace_relu\n",
    "alpha = cfg.alpha\n",
    "w = cfg.w\n",
    "img_str = cfg.img_str\n",
    "if img_str is None:\n",
    "    img_str = os.path.splitext(os.path.basename(target_img_path))[0]\n",
    "gamma = cfg.gamma\n",
    "lr = cfg.lr\n",
    "man_batch_size = cfg.man_batch_size\n",
    "zero_rate = cfg.get(\"zero_rate\", 0.5)\n",
    "tunnel = cfg.get(\"tunnel\", False)\n",
    "if tunnel:\n",
    "    img_str = f\"{img_str}_tunnel\"\n",
    "target_noise = float(cfg.get(\"target_noise\", 0.0))\n",
    "data = cfg.data.dataset_name\n",
    "target_img_path = cfg.target_img_path\n",
    "n_epochs = cfg.epochs\n",
    "layer_str = cfg.model.layer\n",
    "target_neuron = int(cfg.model.target_neuron)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_transforms = hydra.utils.instantiate(dataset.fv_transforms)\n",
    "normalize = hydra.utils.instantiate(cfg.data.normalize)\n",
    "denormalize = hydra.utils.instantiate(cfg.data.denormalize)\n",
    "resize_transforms = hydra.utils.instantiate(cfg.data.resize_transforms)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_path = f\"../results/smas/{dataset_str}/\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise_ds_type = FrequencyManipulationSet if fv_domain == \"freq\" else RGBManipulationSet\n",
    "noise_dataset = noise_ds_type(\n",
    "    image_dims,\n",
    "    target_img_path,\n",
    "    normalize,\n",
    "    denormalize,\n",
    "    image_transforms,\n",
    "    resize_transforms,\n",
    "    n_channels,\n",
    "    fv_sd,\n",
    "    fv_dist,\n",
    "    zero_rate,\n",
    "    tunnel,\n",
    "    target_noise,\n",
    "    device,\n",
    ")\n",
    "train_dataset, test_dataset = hydra.utils.instantiate(\n",
    "    cfg.data.load_function, path=data_dir + cfg.data.data_path\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(train_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(test_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "alphas1 = [\n",
    "    \"1e-4\",\n",
    "    \"3.33e-4\",\n",
    "    \"6.66e-4\",\n",
    "    \"1e-3\",\n",
    "    \"3.33e-3\",\n",
    "    \"6.66e-3\",\n",
    "    \"1e-2\",\n",
    "    \"3.33e-2\",\n",
    "    \"6.66e-2\",\n",
    "    \"1e-1\",\n",
    "    \"1.0\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "default_model = hydra.utils.instantiate(cfg.model.model)\n",
    "if original_weights is not None:\n",
    "    default_model.load_state_dict(torch.load(original_weights, map_location=device))\n",
    "default_model.to(device)\n",
    "default_model.eval()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "before_acc = evaluate(default_model, test_loader, device)\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model_str\": \"Original\",\n",
    "        \"model_str_acc\": \"Original\\n {:0.2f} \\%\".format(before_acc),\n",
    "        \"model\": default_model,\n",
    "        \"acc\": before_acc,\n",
    "        \"loss_m\": 0,\n",
    "        \"loss_p\": 0,\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "for fv_sd in [1e-1]:\n",
    "    for alpha1 in alphas1:\n",
    "        print(\"distribution=\", (fv_dist, fv_sd, man_batch_size))\n",
    "        PATH = \"{}/{}/{}/{}/{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_model.pth\".format(\n",
    "            output_dir,\n",
    "            dataset_str,\n",
    "            cfg.model.model_name,\n",
    "            \"softplus\" if replace_relu else \"relu\",\n",
    "            img_str,\n",
    "            fv_domain,\n",
    "            str(fv_sd),\n",
    "            fv_dist,\n",
    "            str(float(alpha1)),\n",
    "            str(w),\n",
    "            gamma,\n",
    "            lr,\n",
    "            fv_dist,\n",
    "            batch_size,\n",
    "            man_batch_size,\n",
    "        )\n",
    "\n",
    "        img_title = PATH.split(\"/\", 1)[1].split(\"/\", 1)[1].replace(\"pth\", \"jpg\")\n",
    "        model = hydra.utils.instantiate(cfg.model.model)\n",
    "        model.to(device)\n",
    "        print(alpha1)\n",
    "        model_dict = torch.load(PATH, map_location=torch.device(device))\n",
    "        model.load_state_dict(model_dict[\"model\"])\n",
    "        mdict = {\n",
    "            \"model_str\": r\"$\\alpha =$\" + str(sci_notation(float(alpha1))),\n",
    "            \"model_str_acc\": r\"$\\alpha =$\"\n",
    "            + str(sci_notation(float(alpha1)))\n",
    "            + \"\\n {:0.2f} \\%\".format(model_dict[\"after_acc\"]),\n",
    "            \"model\": model,\n",
    "            \"acc\": model_dict[\"after_acc\"],\n",
    "            \"loss_m\": model_dict[\"loss_m\"],\n",
    "            \"loss_p\": model_dict[\"loss_p\"],\n",
    "        }\n",
    "        models.append(mdict)\n",
    "        print(\n",
    "            \"Model accuracy: \", \"\\n {:0.2f} \\%\".format(model_dict[\"after_acc\"])\n",
    "        )\n",
    "        i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manipulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Similarity Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "dist_funcs = [\n",
    "    (r\"SSIM $\\uparrow$\", ssim_dist, r\"SSIM\"),\n",
    "    (r\"LPIPS $\\downarrow$\", alex_lpips, r\"LPIPS\"),\n",
    "    (r\"MSE $\\downarrow$\", mse_dist, r\"MSE\"),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr = 0.1\n",
    "nsteps = 100\n",
    "nvis = 10\n",
    "n_fv_obs = 10 # TODO: Change to 100\n",
    "\n",
    "eval_fv_tuples = [  # (\"normal\", 0.001),\n",
    "    (fv_dist, fv_sd),  # (\"normal\", 0.1), (\"normal\", 1.0)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Qualitative Analysis: Plot 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_by_step_basic = collect_fv_data_by_step(\n",
    "    models=models,\n",
    "    fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "    eval_fv_tuples=eval_fv_tuples,\n",
    "    noise_gen_class=noise_ds_type,\n",
    "    image_dims=image_dims,\n",
    "    target_str=target_img_path,\n",
    "    normalize=normalize,\n",
    "    denormalize=denormalize,\n",
    "    resize_transforms=resize_transforms,\n",
    "    n_channels=n_channels,\n",
    "    layer_str=layer_str,\n",
    "    target_neuron=target_neuron,\n",
    "    nvis=nvis,\n",
    "    n_fv_obs=1,\n",
    "    dist_funcs=dist_funcs,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = results_df_by_step_basic\n",
    "df['model_dist'] = df['model']\n",
    "for dist_str, dist_func, dist_str2 in dist_funcs[:-1]:\n",
    "    if dist_str2 != 'SSIM':\n",
    "        dist_min = df[(df.iter == 0) & (df.step == nsteps) & (df.model.isin([models[s][\"model_str\"] for s in [0, 1, 4, 7, 10]]))][dist_str].min()\n",
    "    else:\n",
    "        dist_min = df[(df.iter == 0) & (df.step == nsteps) & (df.model.isin([models[s][\"model_str\"] for s in [0, 1, 4, 7, 10]]))][dist_str].max()\n",
    "    bool_array = df[dist_str] == dist_min\n",
    "    df[dist_str] = df[dist_str].astype(float)\n",
    "    df[dist_str + \"_corr\"] = df[dist_str].copy().map('{:,.3f}'.format)\n",
    "    df[dist_str + \"_corr\"][bool_array] = r'\\textbf{' + str('{:,.3f}'.format(dist_min)) + r'}'\n",
    "    df['model_dist'] = df['model_dist'] + \"\\n\" + dist_str2 + \": \" + df[dist_str + \"_corr\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic = results_df_by_step_basic[\n",
    "    results_df_by_step_basic[\"step\"] == results_df_by_step_basic[\"step\"].unique()[-1]\n",
    "]\n",
    "results_df_basic_ex = results_df_basic[results_df_basic[\"iter\"] == 0]\n",
    "grid = fv_2d_grid_model_vs_parameters(\n",
    "    results_df_basic_ex[results_df_basic_ex.model.isin([models[s][\"model_str\"] for s in [0, 1, 4, 7, 10]])],\n",
    "    dist=True,\n",
    ")\n",
    "\n",
    "plt.savefig(f\"{save_path}/ssim_alpha_demo.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Select Manipulation Model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T20:45:54.701922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "man_model = 7\n",
    "man_model_str = models[man_model][\"model_str\"]\n",
    "# models[man_model][\"model_str\"] = \"Manipulated\"\n",
    "results_df_by_step_basic = results_df_by_step_basic.replace(\n",
    "    {\"model\": {man_model_str: \"Manipulated\"}}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Plot Images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T20:45:55.389002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "im = Image.fromarray(\n",
    "    (results_df_basic_ex.picture.values[0] * 255).squeeze().astype(np.uint8)\n",
    ")\n",
    "im.save(f\"{save_path}/original_fv.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "im = Image.fromarray(\n",
    "    (results_df_basic_ex.picture.values[man_model] * 255).squeeze().astype(np.uint8),\n",
    ")\n",
    "im.save(f\"{save_path}/manipulated_fv.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Qualitative Analysis: Plot 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_2d_grid_step_vs_model(\n",
    "    results_df_by_step_basic[\n",
    "        results_df_by_step_basic.model.isin(\n",
    "            [models[0][\"model_str\"], \"Manipulated\"]\n",
    "        )\n",
    "    ],\n",
    "    nvis,\n",
    ")\n",
    "plt.savefig(f\"{save_path}/man_am_progress.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Qualitative Analysis: Plot 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "ExecuteTime": {
     "start_time": "2023-11-12T20:45:55.446040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for neuron in range(10):\n",
    "    df_neuron = collect_fv_data(\n",
    "        models=models[0:1] + models[man_model : man_model + 1],\n",
    "        fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "        eval_fv_tuples=[(\"normal\", 0.01)],\n",
    "        noise_gen_class=noise_ds_type,\n",
    "        image_dims=image_dims,\n",
    "        target_str=target_img_path,\n",
    "        normalize=normalize,\n",
    "        denormalize=denormalize,\n",
    "        resize_transforms=resize_transforms,\n",
    "        n_channels=n_channels,\n",
    "        layer_str=layer_str,\n",
    "        target_neuron=neuron,\n",
    "        n_fv_obs=1,\n",
    "        device=device,\n",
    "    )\n",
    "    df = pd.concat([df, df_neuron], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_mnist_output(\n",
    "    df.replace({\"neuron\": MNIST_CLASSES}).replace(\n",
    "        {\"model\": {man_model_str: \"Manipulated\"}}\n",
    "    )\n",
    ")\n",
    "plt.savefig(f\"{save_path}/10_classes_before_after.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "update_font(35)\n",
    "grid = sns.FacetGrid(df.replace({\"neuron\": MNIST_CLASSES}).replace(\n",
    "        {\"model\": {man_model_str: \"After\", \"Original\":\"Before\"}}\n",
    "    ), row='model', col='neuron', margin_titles=True, aspect=0.56)\n",
    "grid.map(lambda x, **kwargs: (plt.imshow(x.values[0], cmap=\"gray\"), plt.grid(False)), 'picture')\n",
    "grid.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "grid.set(xlabel=None, xticklabels=[], yticklabels=[])\n",
    "plt.subplots_adjust(hspace=0.04, wspace=0.04)\n",
    "plt.savefig(f\"{save_path}/small_10_classes_before_after.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantitative Analysis: Plot 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic_100 = collect_fv_data(\n",
    "    models=models,\n",
    "    fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "    eval_fv_tuples=eval_fv_tuples,\n",
    "    noise_gen_class=noise_ds_type,\n",
    "    image_dims=image_dims,\n",
    "    target_str=target_img_path,\n",
    "    normalize=normalize,\n",
    "    denormalize=denormalize,\n",
    "    resize_transforms=resize_transforms,\n",
    "    n_channels=n_channels,\n",
    "    layer_str=layer_str,\n",
    "    target_neuron=target_neuron,\n",
    "    n_fv_obs=n_fv_obs,\n",
    "    dist_funcs=dist_funcs,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_similarity_boxplots_by_dist_func(\n",
    "    results_df_basic_100, \n",
    "    dist_funcs\n",
    ")\n",
    "grid.savefig(f\"{save_path}/boxplot.png\", bbox_inches=\"tight\")\n",
    "# sns.set(rc={'figure.figsize':(12.7,18.6)})\n",
    "# plt.tight_layout()\n",
    "# plt.subplots_adjust(hspace=0.02, wspace=0.02)\n",
    "# plt.figure(figsize=(45,30))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "eval_table = (\n",
    "    results_df_basic_100.groupby([\"model\"])\n",
    "    .describe(include=[float])\n",
    "    .loc[:, (slice(None), [\"mean\", \"std\"])]\n",
    ")\n",
    "\n",
    "eval_table.columns = eval_table.columns.map(\"_\".join)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# save eval_table to ../results folder\n",
    "eval_table.to_csv(f\"{save_path}/eval_table.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "eval_table = (\n",
    "    results_df_basic_100.groupby([\"model\"])\n",
    "    .describe(include=[float])\n",
    "    .loc[:, (slice(None), [\"mean\", \"std\"])]\n",
    ")\n",
    "\n",
    "eval_table.columns = eval_table.columns.map(\"_\".join)\n",
    "for s in [d[0] for d in dist_funcs]:\n",
    "    eval_table[s + \"_mean\"] = eval_table[s + \"_mean\"].map(\"${:,.3f}\".format).astype(str)\n",
    "    eval_table[s + \"_std\"] = eval_table[s + \"_std\"].map(\"{:,.3f}$\".format).astype(str)\n",
    "    eval_table[s] = eval_table[s + \"_mean\"] + \"\\pm\" + eval_table[s + \"_std\"]\n",
    "for s in [\"acc\", \"model_loss_m\", \"model_loss_p\"]:\n",
    "    eval_table[s] = eval_table[s + \"_mean\"]\n",
    "eval_table = eval_table[\n",
    "    [\"acc\"] + [d[0] for d in dist_funcs[::-1]]\n",
    "    ]\n",
    "eval_table[\"acc\"] = eval_table[\"acc\"].map(\"{:,.3f}\".format).astype(str)\n",
    "eval_table = eval_table.reset_index(drop=False)\n",
    "eval_table[\"model\"] = eval_table[\"model\"].str[10:].str.replace(\"odel\", \"Original\")\n",
    "#eval_table[\"model\"][eval_table[\"model\"] != \"Original\"] = eval_table[\"model\"][eval_table[\"model\"] != \"Original\"].apply(sci_notation)\n",
    "\n",
    "eval_table[\"model\"][eval_table[\"model\"] != \"Original\"] = eval_table[\"model\"][\n",
    "    eval_table[\"model\"] != \"Original\"\n",
    "    ].astype(str)\n",
    "eval_table.columns = [\n",
    "                         r\"$\\alpha$\",\n",
    "                         \"Accuracy\"] + [d[0] for d in dist_funcs[::-1]]\n",
    "\n",
    "eval_table = eval_table.reindex(\n",
    "    [len(eval_table) - 1] + [3, 7, 10, 2, 6, 9, 1, 5, 8, 0, 4]\n",
    ")\n",
    "print(eval_table.to_latex(escape=False, index=False))\n",
    "eval_table = (\n",
    "    results_df_basic_100.groupby([\"model\"])\n",
    "    .describe(include=[float])\n",
    "    .loc[:, (slice(None), [\"mean\", \"std\"])]\n",
    ")\n",
    "\n",
    "eval_table.columns = eval_table.columns.map(\"_\".join)\n",
    "for s in [d[0] for d in dist_funcs]:\n",
    "    eval_table[s + \"_mean\"] = (eval_table[s + \"_mean\"] * 100).map(\"${:,.1f}\".format).astype(str)\n",
    "    eval_table[s + \"_std\"] = (eval_table[s + \"_std\"] * 100).map(\"{:,.1f}$\".format).astype(str)\n",
    "    eval_table[s] = eval_table[s + \"_mean\"] + \"\\pm\" + eval_table[s + \"_std\"]\n",
    "for s in [\"acc\", \"model_loss_m\", \"model_loss_p\"]:\n",
    "    eval_table[s] = eval_table[s + \"_mean\"]\n",
    "\n",
    "ssim_means = eval_table[dist_funcs[0][0] + \"_mean\"].str[1:].astype(float).copy().values\n",
    "ssim_means = ssim_means[[11,3,7,10,2,6,9,1,5,8,0,4]] [1: -1]\n",
    "\n",
    "eval_table = eval_table[\n",
    "    [\"acc\"] + [d[0] for d in dist_funcs[::-1] if \"MSE\" in d[0]]\n",
    "    ]\n",
    "eval_table[\"acc\"] = eval_table[\"acc\"].map(\"{:,.3f}\".format).astype(str)\n",
    "eval_table = eval_table.reset_index(drop=False)\n",
    "eval_table[\"model\"] = eval_table[\"model\"].str[10:].str.replace(\"odel\", \"Original\")\n",
    "#eval_table[\"model\"][eval_table[\"model\"] != \"Original\"] = eval_table[\"model\"][eval_table[\"model\"] != \"Original\"].apply(sci_notation)\n",
    "\n",
    "eval_table[\"model\"][eval_table[\"model\"] != \"Original\"] = eval_table[\"model\"][\n",
    "    eval_table[\"model\"] != \"Original\"\n",
    "    ].astype(str)\n",
    "eval_table.columns = [\n",
    "                         r\"$\\alpha$\",\n",
    "                         \"Accuracy\"] + [d[0] for d in dist_funcs[::-1] if \"MSE\" in d[0]]\n",
    "\n",
    "eval_table = eval_table.reindex(\n",
    "    [len(eval_table) - 1] + [3, 7, 10, 2, 6, 9, 1, 5, 8, 0, 4]\n",
    ")\n",
    "print(eval_table.to_latex(escape=False, index=False))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_df_basic_ex = results_df_basic_ex.reset_index(drop=True)\n",
    "def plot_ssim_examples():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = imscatter(np.arange(1,11), ssim_means, results_df_basic_ex['picture'], zoom=0.95, ax=ax)\n",
    "    ax.plot(np.arange(1,11), ssim_means)\n",
    "    return ax, fig\n",
    "\n",
    "def imscatter(x, y, images, ax=None, zoom=1):\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    i = 1\n",
    "    for x0, y0 in zip(x, y):\n",
    "        image = images[i].squeeze()\n",
    "        if len(image.shape) == 2:\n",
    "            cmap = 'gray'\n",
    "        else:\n",
    "            cmap = None\n",
    "        im = OffsetImage(images[i].squeeze(), zoom=zoom, cmap=cmap)\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "        i += 1\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return ax\n",
    "\n",
    "ax, fig = plot_ssim_examples()\n",
    "plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"axes.titlesize\": 10,\n",
    "        \"axes.labelsize\": 13,\n",
    "        \"font.size\": 10,\n",
    "        \"font.family\": \"Helvetica\",\n",
    "        \"xtick.labelsize\": 12,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        'text.latex.preamble': r\"\\usepackage{amsmath}\\usepackage{color}\",\n",
    "    })\n",
    "ax.set_xticks(range(1, 11), eval_table[r\"$\\alpha$\"][1:-1], rotation='vertical')\n",
    "#plt.gca().set_aspect(7)\n",
    "#plt.ylim([min(ssim_means)-0.08, max(ssim_means)+0.08])\n",
    "#plt.xlim([0.4, 10.6])\n",
    "ax.set_xlabel(r'$\\alpha$', fontsize=21)\n",
    "ax.set_ylabel(r'SSIM', fontsize=12)\n",
    "plt.savefig(f\"{save_path}/ssim_dynamics.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantitative Analysis: Plot 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T20:45:55.446465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_by_step_basic_100 = collect_fv_data_by_step(\n",
    "    models=models[0:1] + models[man_model : man_model + 1],\n",
    "    fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "    eval_fv_tuples=eval_fv_tuples,\n",
    "    noise_gen_class=noise_ds_type,\n",
    "    image_dims=image_dims,\n",
    "    target_str=target_img_path,\n",
    "    normalize=normalize,\n",
    "    denormalize=denormalize,\n",
    "    resize_transforms=resize_transforms,\n",
    "    n_channels=n_channels,\n",
    "    layer_str=layer_str,\n",
    "    target_neuron=target_neuron,\n",
    "    nvis=nsteps,\n",
    "    n_fv_obs=n_fv_obs,\n",
    "    dist_funcs=dist_funcs,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_2d_grid_model_by_step_similarity(\n",
    "    results_df_by_step_basic_100.replace(\n",
    "        {\"model\": {man_model_str: \"Manipulated\"}}\n",
    "    ),\n",
    "    dist_funcs,\n",
    ")\n",
    "grid.savefig(f\"{save_path}/similarity_step.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Natural Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(train_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "before_a, target_b, idxs, images_b = get_encodings(\n",
    "    models[0][\"model\"], layer_str, [test_loader], device\n",
    ")\n",
    "after_a, target_a, idxs, images_a = get_encodings(\n",
    "    models[man_model][\"model\"], layer_str, [test_loader], device\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Before\")\n",
    "fig1 = activation_max_top_k(before_a[:, target_neuron], denormalize, images_b, [0], \"\")\n",
    "fig1.savefig(f\"{save_path}/top_4_before.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"After\")\n",
    "fig2 = activation_max_top_k(after_a[:, target_neuron], denormalize, images_a, [0], \"\")\n",
    "fig2.savefig(f\"{save_path}/top_4_after.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Jaccard similarity coefficient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "top_idxs_before = list(np.argsort(before_a[:, target_neuron])[::-1][:100])\n",
    "top_idxs_after = list(np.argsort(after_a[:, target_neuron])[::-1][:100])\n",
    "print(len([s for s in top_idxs_before if s in top_idxs_after]) / len(list(set(top_idxs_before + top_idxs_after))))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUC Value BEFORE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T20:45:55.446698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torchmetrics import AUROC\n",
    "\n",
    "metric = AUROC(task=\"binary\")\n",
    "metric(\n",
    "    torch.tensor(before_a[:, target_neuron]), torch.tensor(target_b == target_neuron)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUC Value AFTER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "metric(torch.tensor(after_a[:, target_neuron]), torch.tensor(target_a == target_neuron))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantitative Analysis: Plot 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "defense_strategies = {\n",
    "    \"None\": {\"lr\": lr, \"n_steps\": nsteps},\n",
    "    \"GC\": {\"lr\": lr, \"n_steps\": nsteps, \"grad_clip\": 1.0},\n",
    "    \"TR\": {\n",
    "        \"lr\": lr,\n",
    "        \"n_steps\": nsteps,\n",
    "        \"tf\": torchvision.transforms.Compose(image_transforms),\n",
    "    },\n",
    "    \"Adam\": {\n",
    "        \"lr\": lr/10,\n",
    "        \"n_steps\": nsteps,\n",
    "        \"adam\": True,\n",
    "    },\n",
    "    \"Adam + GC + TR\": {\n",
    "        \"lr\": lr/10,\n",
    "        \"n_steps\": nsteps,\n",
    "        \"adam\": True,\n",
    "        \"tf\": torchvision.transforms.Compose(image_transforms),\n",
    "        \"grad_clip\": 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for strategy in defense_strategies:\n",
    "    strategy_df = collect_fv_data(\n",
    "        models=[models[0], models[man_model]],\n",
    "        fv_kwargs=defense_strategies[strategy],\n",
    "        eval_fv_tuples=[(\"normal\", 0.01)],\n",
    "        noise_gen_class=noise_ds_type,\n",
    "        image_dims=image_dims,\n",
    "        target_str=target_img_path,\n",
    "        normalize=normalize,\n",
    "        denormalize=denormalize,\n",
    "        resize_transforms=resize_transforms,\n",
    "        n_channels=n_channels,\n",
    "        layer_str=layer_str,\n",
    "        target_neuron=target_neuron,\n",
    "        n_fv_obs=n_fv_obs,\n",
    "        dist_funcs=[],\n",
    "        folder=\"../results/smas/{}/figure_6/\".format(dataset_str),\n",
    "        title_str=strategy,\n",
    "        device=device,\n",
    "    )\n",
    "    strategy_df[\"defense_strategy\"] = strategy\n",
    "    df = pd.concat([df, strategy_df], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "strategies_result = pd.DataFrame(\n",
    "    index=list(defense_strategies.keys()),\n",
    "    columns=[\"Similarity To Target\", \"Similarity To Pre-Manipulation\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "image = Image.open(target_img_path)\n",
    "\n",
    "if n_channels == 1:\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "target = torchvision.transforms.ToTensor()(image).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for s in defense_strategies:\n",
    "    original_fvs = df[\"picture\"][\n",
    "        (df[\"model\"] == \"Original\") & (df[\"defense_strategy\"] == s)\n",
    "    ].values\n",
    "    man_fvs = df[\"picture\"][\n",
    "        (df[\"model\"] != \"Original\") & (df[\"defense_strategy\"] == s)\n",
    "    ].values\n",
    "    original_fvs = torch.tensor(np.array([f for f in original_fvs]))\n",
    "    man_fvs = torch.tensor(np.array([f for f in man_fvs])).to(device)\n",
    "    strategies_result.at[s, \"Similarity To Target\"] = \"{:.4f}\".format(cdist_mean(target.permute((1,2,0)), man_fvs, alex_lpips))\n",
    "    strategies_result.at[s, \"Similarity To Pre-Manipulation\"] = \"{:.4f}\".format(cdist_mean(original_fvs.to(device), man_fvs, alex_lpips))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plot_df = df[df.iter==0].drop_duplicates(subset=[\"defense_strategy\", \"model\"], keep=\"last\")\n",
    "plot_df = plot_df[[\"model\", \"defense_strategy\", \"picture\"]].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set(font_scale=2)\n",
    "grid = fv_2d_grid_model_vs_defense(plot_df.replace(\n",
    "    {\"model\": {man_model_str: \"Manipulated\"}, \"defense_strategy\": {\"Adam + GC + TR\": \"GC+TR+\\nAdam\"}}\n",
    "))\n",
    "grid.savefig(f\"{save_path}/qual_defense.png\", bbox_inches=\"tight\")\n",
    "grid.add_legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\n",
    "    strategies_result.to_latex(\n",
    "        index=True,\n",
    "        formatters={\"name\": str.upper},\n",
    "        float_format=\"{:.4f}\".format,\n",
    "        escape=False,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Distance to Target: n-AMS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": "cdist_mean(target.permute((1,2,0)), denormalize(torch.tensor(images_a)).permute(0,2,3,1)[top_idxs_after[:100]].to(device), alex_lpips)",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
