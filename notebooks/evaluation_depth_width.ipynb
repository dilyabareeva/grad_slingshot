{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Template"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import hydra\n",
    "import itertools\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from models import evaluate\n",
    "from core.custom_dataset import CustomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from utils import ssim_dist, alex_lpips, mse_dist\n",
    "from core.manipulation_set import FrequencyManipulationSet, RGBManipulationSet\n",
    "from plotting import (\n",
    "    collect_fv_data,\n",
    "    fv_2d_grid_step_vs_model,\n",
    "    collect_fv_data_by_step,\n",
    "    fv_2d_grid_model_depth_vs_width,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.ioff()\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/Library/TeX/texbin\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.random.seed(27)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.set_theme()\n",
    "sns.set_palette(\"pastel\")\n",
    "sns.set(font_scale=1.2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config_cifar_arch\",  # alternatively, \"config_mnist\"\n",
    "        overrides=[\n",
    "        ],\n",
    "    )\n",
    "device = \"cuda:0\"\n",
    "original_weights = cfg.model.get(\"original_weights_path\", None)\n",
    "if original_weights:\n",
    "    original_weights = \"{}/{}\".format(cfg.model_dir, original_weights)\n",
    "data_dir = cfg.data_dir\n",
    "model_dir = cfg.model_dir\n",
    "output_dir = cfg.output_dir\n",
    "dataset = cfg.data\n",
    "dataset_str = cfg.data.dataset_name\n",
    "default_layer_str = cfg.model.layer\n",
    "n_out = cfg.model.n_out\n",
    "image_dims = cfg.data.image_dims\n",
    "n_channels = cfg.data.n_channels\n",
    "class_dict_file = cfg.data.get(\"class_dict_file\", None)\n",
    "if class_dict_file is not None:\n",
    "    class_dict_file = \".\" + class_dict_file\n",
    "fv_sd = float(cfg.fv_sd)\n",
    "fv_dist = cfg.fv_dist\n",
    "fv_domain = cfg.fv_domain\n",
    "target_img_path = cfg.target_img_path\n",
    "batch_size = cfg.batch_size\n",
    "train_original = cfg.train_original\n",
    "replace_relu = cfg.replace_relu\n",
    "alpha = cfg.alpha\n",
    "w = cfg.w\n",
    "img_str = cfg.img_str\n",
    "if img_str is None:\n",
    "    img_str = os.path.splitext(os.path.basename(target_img_path))[0]\n",
    "gamma = cfg.gamma\n",
    "lr = cfg.lr\n",
    "man_batch_size = cfg.man_batch_size\n",
    "zero_rate = cfg.get(\"zero_rate\", 0.5)\n",
    "tunnel = cfg.get(\"tunnel\", False)\n",
    "if tunnel:\n",
    "    img_str = f\"{img_str}_tunnel\"\n",
    "target_noise = float(cfg.get(\"target_noise\", 0.0))\n",
    "data = cfg.data.dataset_name\n",
    "target_img_path = cfg.target_img_path\n",
    "n_epochs = cfg.epochs\n",
    "layer_str = cfg.model.layer\n",
    "target_neuron = int(cfg.model.target_neuron)\n",
    "image_transforms = hydra.utils.instantiate(dataset.fv_transforms)\n",
    "normalize = hydra.utils.instantiate(cfg.data.normalize)\n",
    "denormalize = hydra.utils.instantiate(cfg.data.denormalize)\n",
    "resize_transforms = hydra.utils.instantiate(cfg.data.resize_transforms)\n",
    "save_path = f\"../results/smas/{dataset_str}/\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise_ds_type = FrequencyManipulationSet if fv_domain == \"freq\" else RGBManipulationSet\n",
    "noise_dataset = noise_ds_type(\n",
    "    image_dims,\n",
    "    target_img_path,\n",
    "    normalize,\n",
    "    denormalize,\n",
    "    image_transforms,\n",
    "    resize_transforms,\n",
    "    n_channels,\n",
    "    fv_sd,\n",
    "    fv_dist,\n",
    "    zero_rate,\n",
    "    tunnel,\n",
    "    target_noise,\n",
    "    device,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset, test_dataset = hydra.utils.instantiate(\n",
    "    cfg.data.load_function, path=data_dir + cfg.data.data_path\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(train_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CustomDataset(test_dataset, class_dict_file),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": "kws = list(itertools.product([\"A\", \"B\", \"C\", \"D\"], [8, 16, 32, 64]))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "models = []\n",
    "original_models = []\n",
    "\n",
    "for key, width in kws:\n",
    "    model_name = \"cifar_mvgg_\" + key + str(width)\n",
    "    with initialize(version_base=None, config_path=\"../config\"):\n",
    "        cfg_model = compose(\n",
    "            config_name=\"config_cifar\",  # alternatively, \"config_mnist\"\n",
    "            overrides=[\n",
    "                f\"model.model_name={model_name}\",\n",
    "                f\"model.model.cfg={key}\",\n",
    "                f\"model.model.width={width}\"\n",
    "            ],\n",
    "        )\n",
    "    original_weights = f\"{model_name}.pth\"\n",
    "    if original_weights:\n",
    "        original_weights = \"{}/{}\".format(model_dir, original_weights)\n",
    "    default_model = hydra.utils.instantiate(cfg_model.model.model)\n",
    "    if original_weights is not None:\n",
    "        default_model.load_state_dict(torch.load(original_weights, map_location=device))\n",
    "    default_model.to(device)\n",
    "    default_model.eval()\n",
    "\n",
    "    before_acc = evaluate(default_model, test_loader, device)\n",
    "\n",
    "    mdict = {\n",
    "        \"model_str\": f\"Original\\n {model_name}\",\n",
    "        \"model_str_acc\": \"{:0.2f} \\%\".format(before_acc),\n",
    "        \"model\": default_model,\n",
    "        \"acc\": before_acc,\n",
    "        \"loss_m\": 0,\n",
    "        \"loss_p\": 0,\n",
    "    }\n",
    "    original_models.append(mdict)\n",
    "\n",
    "    PATH = \"{}/{}/{}/{}/{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_model.pth\".format(\n",
    "        output_dir,\n",
    "        dataset_str,\n",
    "        model_name,\n",
    "        \"softplus\" if replace_relu else \"relu\",\n",
    "        img_str,\n",
    "        fv_domain,\n",
    "        str(fv_sd),\n",
    "        fv_dist,\n",
    "        str(float(alpha)),\n",
    "        str(w),\n",
    "        gamma,\n",
    "        lr,\n",
    "        fv_dist,\n",
    "        batch_size,\n",
    "        man_batch_size,\n",
    "    )\n",
    "\n",
    "    img_title = PATH.split(\"/\", 1)[1].split(\"/\", 1)[1].replace(\"pth\", \"jpg\")\n",
    "    model = hydra.utils.instantiate(cfg_model.model.model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model_dict = torch.load(PATH, map_location=torch.device(device))\n",
    "    model.load_state_dict(model_dict[\"model\"])\n",
    "    mdict = {\n",
    "        \"model_str\": model_name,\n",
    "        \"model_str_acc\": \"{:0.2f} \\%\".format(model_dict[\"after_acc\"] - before_acc),\n",
    "        \"model\": model,\n",
    "        \"acc\": model_dict[\"after_acc\"],\n",
    "        \"loss_m\": model_dict[\"loss_m\"],\n",
    "        \"loss_p\": model_dict[\"loss_p\"],\n",
    "    }\n",
    "    models.append(mdict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "lr = cfg.eval_lr\n",
    "nsteps = cfg.eval_nsteps\n",
    "nvis = 10\n",
    "n_fv_obs = 100 # TODO: Change to 100\n",
    "\n",
    "eval_fv_tuples = [  # (\"normal\", 0.001),\n",
    "    (cfg.eval_fv_dist, float(cfg.eval_fv_sd)),  # (\"normal\", 0.1), (\"normal\", 1.0)\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "## Define Similarity Functions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dist_funcs = [\n",
    "    (r\"SSIM $\\uparrow$\", ssim_dist, r\"SSIM\"),\n",
    "    (r\"LPIPS $\\downarrow$\", alex_lpips, r\"LPIPS\"),\n",
    "    (r\"MSE $\\downarrow$\", mse_dist, r\"MSE\"),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Qualitative Analysis: Plot 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_by_step_basic = collect_fv_data_by_step(\n",
    "    models=models,\n",
    "    fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "    eval_fv_tuples=eval_fv_tuples,\n",
    "    noise_gen_class=noise_ds_type,\n",
    "    image_dims=image_dims,\n",
    "    target_str=target_img_path,\n",
    "    normalize=normalize,\n",
    "    denormalize=denormalize,\n",
    "    resize_transforms=resize_transforms,\n",
    "    n_channels=n_channels,\n",
    "    layer_str=layer_str,\n",
    "    target_neuron=target_neuron,\n",
    "    nvis=nvis,\n",
    "    n_fv_obs=1,\n",
    "    dist_funcs=dist_funcs,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic = results_df_by_step_basic[\n",
    "    results_df_by_step_basic[\"step\"] == results_df_by_step_basic[\"step\"].unique()[-1]\n",
    "]\n",
    "results_df_basic_ex = results_df_basic[results_df_basic[\"iter\"] == 0]\n",
    "results_df_basic_ex[\"key\"] = results_df_basic_ex[\"model\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1][:1]\n",
    ")\n",
    "results_df_basic_ex[\"width\"] = r\"$\\times$\" + results_df_basic_ex[\"model\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1][1:]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# iterate through all array in results_df cells and save into a folder as image\n",
    "for i in range(len(results_df_basic_ex)):\n",
    "    im = Image.fromarray((results_df_basic_ex.picture.values[i] * 255).astype(np.uint8))\n",
    "    #save with a str consisting of key and width values from df\n",
    "    im.save(f\"{save_path}/{results_df_basic_ex.key.values[i]}_{results_df_basic_ex.width.values[i][7:]}.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_2d_grid_model_depth_vs_width(\n",
    "    results_df_basic_ex,\n",
    ")\n",
    "plt.subplots_adjust(hspace=0.22, wspace=0.02)\n",
    "#plt.savefig(f\"{save_path}/plot_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic_og = collect_fv_data(\n",
    "    models=original_models,\n",
    "    fv_kwargs={\"lr\": lr, \"n_steps\": nsteps,},\n",
    "    eval_fv_tuples=eval_fv_tuples,\n",
    "    noise_gen_class=noise_ds_type,\n",
    "    image_dims=image_dims,\n",
    "    target_str=target_img_path,\n",
    "    normalize=normalize,\n",
    "    denormalize=denormalize,\n",
    "    resize_transforms=resize_transforms,\n",
    "    n_channels=n_channels,\n",
    "    layer_str=layer_str,\n",
    "    target_neuron=target_neuron,\n",
    "    n_fv_obs=1,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic_ex = results_df_basic_og\n",
    "results_df_basic_ex[\"key\"] = results_df_basic_ex[\"model\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1][:1]\n",
    ")\n",
    "results_df_basic_ex[\"width\"] = r\"$\\times$\" + results_df_basic_ex[\"model\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1][1:]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# iterate through all array in results_df cells and save into a folder as image\n",
    "for i in range(len(results_df_basic_ex)):\n",
    "    im = Image.fromarray((results_df_basic_ex.picture.values[i] * 255).astype(np.uint8))\n",
    "    #save with a str consisting of key and width values from df\n",
    "    im.save(f\"{save_path}/non_man_{results_df_basic_ex.key.values[i]}_{results_df_basic_ex.width.values[i][7:]}.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_2d_grid_model_depth_vs_width(\n",
    "    results_df_basic_ex,\n",
    ")\n",
    "# plt.subplots_adjust(hspace=0.1, wspace=0.0)\n",
    "plt.savefig(f\"{save_path}/plot_1b.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.fromarray((results_df_basic_ex.picture.values[0] * 255).astype(np.uint8))\n",
    "im.save(f\"{save_path}/original_fv.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Qualitative Analysis: Plot 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "grid = fv_2d_grid_step_vs_model(results_df_by_step_basic, nvis)\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.0)\n",
    "plt.savefig(f\"{save_path}/plot_2.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Qualitative Analysis: Plot 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for neuron in range(10):\n",
    "    df_neuron = collect_fv_data(\n",
    "        models=models,\n",
    "        fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "        eval_fv_tuples=eval_fv_tuples,\n",
    "        noise_gen_class=noise_ds_type,\n",
    "        image_dims=image_dims,\n",
    "        target_str=target_img_path,\n",
    "        normalize=normalize,\n",
    "        denormalize=denormalize,\n",
    "        resize_transforms=resize_transforms,\n",
    "        n_channels=n_channels,\n",
    "        layer_str=layer_str,\n",
    "        target_neuron=neuron,\n",
    "        n_fv_obs=1,\n",
    "        device=device,\n",
    "    )\n",
    "    df = pd.concat([df, df_neuron], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LateX Table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic = collect_fv_data(\n",
    "    models=models,\n",
    "    fv_kwargs={\"lr\": lr, \"n_steps\": nsteps},\n",
    "    eval_fv_tuples=eval_fv_tuples,\n",
    "    noise_gen_class=noise_ds_type,\n",
    "    image_dims=image_dims,\n",
    "    target_str=target_img_path,\n",
    "    normalize=normalize,\n",
    "    denormalize=denormalize,\n",
    "    resize_transforms=resize_transforms,\n",
    "    n_channels=n_channels,\n",
    "    layer_str=layer_str,\n",
    "    target_neuron=target_neuron,\n",
    "    dist_funcs=dist_funcs,\n",
    "    n_fv_obs=n_fv_obs,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df_basic[\"key\"] = results_df_basic[\"model\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1][:1]\n",
    ")\n",
    "results_df_basic[\"width\"] = results_df_basic[\"model\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1][1:]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "eval_table = results_df_basic.copy()\n",
    "eval_table = eval_table[\n",
    "    [\"acc\", r\"MSE $\\downarrow$\", r\"SSIM $\\uparrow$\", \"key\", \"width\"]\n",
    "]\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "#eval_table = eval_table.round(2).astype(str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df1 = pd.pivot_table(eval_table, values=r\"MSE $\\downarrow$\", index=['key'], columns=[\"width\"], aggfunc=\"mean\", fill_value=0).round(3).astype(str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df2 = pd.pivot_table(eval_table, values=r\"MSE $\\downarrow$\", index=['key'], columns=[\"width\"], aggfunc=\"std\", fill_value=0).round(3).astype(str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mvgg_eval_table = r'$' + df1 + r'\\pm' + df2 + r'$'"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mvgg_eval_table = mvgg_eval_table[['8','16','32','64']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(mvgg_eval_table.to_latex(escape=False, float_format=\"{:.3f}\".format))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
