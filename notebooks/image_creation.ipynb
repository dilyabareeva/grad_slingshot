{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from models import evaluate\n",
    "from core.custom_dataset import CustomDataset\n",
    "from torch_dreams.auto_image_param import AutoImageParam\n",
    "import torchvision\n",
    "from core.noise_generator import (\n",
    "    FrequencyManipulationSet,\n",
    "    RGBManipulationSet,\n",
    "    RobustFrequencyManipulationSet,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:53.741655Z",
     "start_time": "2024-05-26T15:32:50.361091Z"
    }
   },
   "id": "b78580995a9b175e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = \"miniimagenet\"\n",
    "model = \"rs50\"\n",
    "batch_size = \"16\"\n",
    "img_str = \"dalmatian\"\n",
    "# alpha = 0.0\n",
    "# lr = 1e-06\n",
    "target_img_path = \"./assets/adv_train/dalmatian.jpg\"\n",
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "            f\"data={data}\",\n",
    "            f\"model={model}\",\n",
    "            f\"batch_size={batch_size}\",\n",
    "            f\"target_img_path={target_img_path}\",\n",
    "            # f\"alpha={alpha}\", f\"lr={lr}\",\n",
    "            # f\"img_str={img_str}\",# f\"lr={lr}\"\n",
    "        ],\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:53.785294Z",
     "start_time": "2024-05-26T15:32:53.737063Z"
    }
   },
   "id": "d2a5043f1ba0fb87"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = \"cuda:1\"\n",
    "original_weights = cfg.model.get(\"original_weights_path\", None)\n",
    "if original_weights:\n",
    "    original_weights = \"{}/{}\".format(cfg.model_dir, original_weights)\n",
    "data_dir = cfg.data_dir\n",
    "output_dir = cfg.output_dir\n",
    "dataset = cfg.data\n",
    "input_layer_str = cfg.model.get(\"input_layer\", None)\n",
    "layer_str = cfg.model.layer\n",
    "n_out = cfg.model.n_out\n",
    "image_dims = cfg.data.image_dims\n",
    "n_channels = cfg.data.n_channels\n",
    "class_dict_file = \".\" + cfg.data.get(\"class_dict_file\", None)\n",
    "target_neuron = int(cfg.model.target_neuron)\n",
    "fv_sd = float(cfg.fv_sd)\n",
    "fv_dist = cfg.fv_dist\n",
    "fv_domain = cfg.fv_domain\n",
    "target_img_path = cfg.target_img_path\n",
    "batch_size = cfg.batch_size\n",
    "train_original = cfg.train_original\n",
    "replace_relu = cfg.replace_relu\n",
    "alpha = cfg.alpha\n",
    "w = cfg.w\n",
    "img_str = cfg.img_str\n",
    "gamma = cfg.gamma\n",
    "lr = cfg.lr\n",
    "sample_batch_size = cfg.sample_batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:53.793149Z",
     "start_time": "2024-05-26T15:32:53.787871Z"
    }
   },
   "id": "d5b6b42e4139c6ac"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "transforms = hydra.utils.instantiate(dataset.fv_transforms)\n",
    "normalize = hydra.utils.instantiate(cfg.data.normalize)\n",
    "denormalize = hydra.utils.instantiate(cfg.data.denormalize)\n",
    "resize_transforms = hydra.utils.instantiate(cfg.data.resize_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:53.818673Z",
     "start_time": "2024-05-26T15:32:53.790762Z"
    }
   },
   "id": "6c8402ddb5caa1f7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "noise_dataset = (\n",
    "    FrequencyManipulationSet(\n",
    "        image_dims,\n",
    "        \".\" + target_img_path,\n",
    "        normalize,\n",
    "        denormalize,\n",
    "        transforms,\n",
    "        resize_transforms,\n",
    "        n_channels,\n",
    "        1e-9,\n",
    "        \"normal\",\n",
    "        device,\n",
    "    )\n",
    "    if fv_domain == \"freq\"\n",
    "    else RGBManipulationSet(\n",
    "        image_dims,\n",
    "        \".\" + target_img_path,\n",
    "        normalize,\n",
    "        denormalize,\n",
    "        transforms,\n",
    "        resize_transforms,\n",
    "        n_channels,\n",
    "        1e-9,\n",
    "        \"normal\",\n",
    "        device,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:57.469645Z",
     "start_time": "2024-05-26T15:32:53.816886Z"
    }
   },
   "id": "addead23b0f86519"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = hydra.utils.instantiate(cfg.model.model)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:58.474119Z",
     "start_time": "2024-05-26T15:32:57.469481Z"
    }
   },
   "id": "9de403e8c5a69e5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m net\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      6\u001B[0m f \u001B[38;5;241m=\u001B[39m noise_dataset\u001B[38;5;241m.\u001B[39mforward\n\u001B[0;32m----> 7\u001B[0m noise_dataset\u001B[38;5;241m.\u001B[39mparam \u001B[38;5;241m=\u001B[39m noise_dataset\u001B[38;5;241m.\u001B[39mparametrize(\u001B[43mnoise_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoise_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m1.005\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5e-8\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      8\u001B[0m tstart \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(noise_dataset\u001B[38;5;241m.\u001B[39mparam)\u001B[38;5;66;03m# + noise_dataset.get_init_value()\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/grad-slingshot/core/noise_generator.py:150\u001B[0m, in \u001B[0;36mFrequencyManipulationSet.normalize\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnormalize\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/datascience/lib/python3.11/site-packages/torch_dreams/utils.py:115\u001B[0m, in \u001B[0;36mnormalize\u001B[0;34m(x, device)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnormalize\u001B[39m(x, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 115\u001B[0m         \u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mConstants\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimagenet_mean\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m     ) \u001B[38;5;241m/\u001B[39m Constants\u001B[38;5;241m.\u001B[39mimagenet_std[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "net = model\n",
    "man_index = target_neuron\n",
    "net.eval()\n",
    "f = noise_dataset.__call__\n",
    "noise_dataset.param = noise_dataset.parametrize(noise_dataset.normalize(noise_dataset.target/1.005 + 5e-8))\n",
    "tstart = copy.deepcopy(noise_dataset.param)# + noise_dataset.get_init_value()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:58.582458Z",
     "start_time": "2024-05-26T15:32:58.483078Z"
    }
   },
   "id": "75dc3c0d7834330e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# tstart = tstart.detach()\n",
    "# rgb tensor, where red tensor is all 1's and the rest is 0s\n",
    "rgb = torch.zeros_like(tstart)\n",
    "rgb[:, 0, :, :] = 0.1\n",
    "fwrd = copy.deepcopy(noise_dataset.target).requires_grad_().to(device)\n",
    "#tf = v2.RandAugment()\n",
    "#fwrd = tf(fwrd) #+ rgb #+ torch.rand_like(fwrd)*0.2\n",
    "param = noise_dataset.parametrize(noise_dataset.normalize(fwrd/1.005 + 5e-8))\n",
    "param = noise_dataset.param.requires_grad_()\n",
    "#param +=  torch.rand_like(param) * 0.04 - 0.02 * torch.ones_like(param)\n",
    "y_t = net.__call__(f(param))[0]\n",
    "print(torch.autograd.grad(y_t[man_index], param, create_graph=True)[0].abs().pow(2).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.534054Z"
    }
   },
   "id": "40f644d9e1305b13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " #fwrd = noise_dataset.to_image(tstart/1.1)\n",
    "plt.imshow(noise_dataset.to_image(param)[0].permute(1, 2, 0).detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.535661Z"
    }
   },
   "id": "570e158128a76662"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "original = copy.deepcopy(noise_dataset.param)\n",
    "tstart = copy.deepcopy(noise_dataset.param)# + noise_dataset.get_init_value()\n",
    "tstart = tstart.to(device).requires_grad_()\n",
    "target = noise_dataset.target.to(device)\n",
    "optimizer_fv = torch.optim.Adam([tstart], lr=0.00001)\n",
    "torch.set_printoptions(precision=8)\n",
    "loss = 10000\n",
    "n = 0\n",
    "while 1:\n",
    "    optimizer_fv.zero_grad()\n",
    "\n",
    "    y_t = net.__call__(f(tstart))[0]\n",
    "    grd = torch.autograd.grad(y_t[man_index], tstart, create_graph=True)\n",
    "    loss = grd[0].pow(2).mean()\n",
    "    if loss < 0.005:\n",
    "        break\n",
    "    #loss = grd[0].abs().max().pow(2)\n",
    "    if n % 100 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    #torch.nn.utils.clip_grad_norm_([tstart], grad_clip)\n",
    "    optimizer_fv.step()\n",
    "    n+=1\n",
    "    \n",
    "print(grd[0].abs().pow(2).mean())\n",
    "print(grd[0].abs().max().pow(2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.538477Z"
    }
   },
   "id": "9730633e60e6295b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVE = tstart\n",
    "torch.save(tstart, \"../assets/adv_train/dalmatian_opt.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.540043Z"
    }
   },
   "id": "828e2e30670b993c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fwrd = noise_dataset.to_image(tstart)\n",
    "plt.imshow(fwrd[0].permute(1, 2, 0).detach().cpu().numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:58.587061Z",
     "start_time": "2024-05-26T15:32:58.586823Z"
    }
   },
   "id": "4cf8d6552e77dcd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(fwrd, \"../assets/adv_train/dalmatian_opt.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.586932Z"
    }
   },
   "id": "60c74ca034d928af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param = noise_dataset.parametrize(noise_dataset.normalize(fwrd))\n",
    "y_t = net.__call__(f(param))[0]\n",
    "print(torch.autograd.grad(y_t[man_index], param, create_graph=True)[0].abs().pow(2).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.587040Z"
    }
   },
   "id": "edbb5f7551dead8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fwrd = fwrd+1e-6\n",
    "plt.imshow(fwrd[0].permute(1, 2, 0).detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T15:32:58.606828Z",
     "start_time": "2024-05-26T15:32:58.587119Z"
    }
   },
   "id": "8c55fd0d4caba9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "torchvision.utils.save_image(fwrd, \"../assets/adv_train/dalmatian_opt.jpg\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ce5b3deeff05371"
  },
  {
   "cell_type": "markdown",
   "source": [
    "param = noise_dataset.parametrize(noise_dataset.normalize(fwrd))\n",
    "y_t = net.__call__(f(param))[0]\n",
    "print(torch.autograd.grad(y_t[man_index], param, create_graph=True)[0].abs().pow(2).mean())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d122638e2d29622"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-26T15:32:58.587184Z"
    }
   },
   "id": "eb96f89dff67659c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
